
# not currently implemented
# patchsize: 0

features:
  - name: my pickle files
    type: pickle
    files:
      covariates: /home/masoud/GA_data/GA-cover2/features.pk
      targets: /home/masoud/GA_data/GA-cover2/targets.pk
      rawcovariates: /home/masoud/GA_data/GA-cover2/rawcovariates.csv
      rawcovariates_mask: rawcovariates_mask.csv

  - name: my features 1
    type: ordinal
    files:
      # - path: /home/masoud/GA_data/GA-cover2/Th_v1.tif
      # - list: /home/masoud/GA_data/GA_Cover2_sirsam_LLC/sirsam_covariates_convolved.txt
      - directory: /home/masoud/GA_data/GA-cover2
    # transforms are performed in order
    transforms:
      - centre
      - standardise
    imputation: none
  
  - name: my features 2
    type: categorical
    files:
      # - path: /home/masoud/GA_data/GA-cover2/Th_v1.tif
      # - list: /path/to/csv_file.csv
      - directory: /home/masoud/GA_data/GA-cover2/cat_datasets
    # transforms are performed in order
    transforms:
      - randomhot:
          n_features: 10
          seed: 1
    imputation: none

# mask file used for masking prediction grid
# Mask with values=retain will be predicted
mask:
  file: /home/masoud/GA_data/GA-cover2/mask/old_mask_test.tif
  retain: 1

preprocessing:
  # imputation: none
  # imputation: gaus
  # imputation: nn
  imputation: mean

  transforms:
    # - whiten:
        # keep_fraction: 0.8

# resample: choice (value, spatial)
# bootstrap: bool, sampling with or without replacement
# output_samples: number of output samples kept
# bins: for value based resampling only. Number of bins to sample from.
# rows and cols: for spatial resampling, sample from rows X cols tiles
# resampling is performed in sequence. The order of spatial/value is important.
targets:
  file: /home/masoud/GA_data/GA-cover2/geochem_sites.shp
  property: K_ppm_imp_
  resample:
    - value:
        arguments:
          bins: 10
          bootstrap: True
          output_samples: 500
    - spatial:
        arguments:
          rows: 4
          cols: 4
          bootstrap: True
          output_samples: 500

clustering:
  file: /home/masoud/GA_data/GA-cover2/geochem_sites_class1.shp
  property: class
  algorithm: kmeans
  arguments:
    n_classes: 12
    oversample_factor: 5

# target_transform: target transform (choice: stardardise, sqrt, log, identity,
# logistic, rank, kde)

learning:
    # algorithm: sgdapproxgp
    # arguments:
    #     target_transform: standardise
    #     kern: rbf
    #     lenscale: 1000
    #     ard: True
    #     maxiter: 5000
    #     nbases: 50
    #     random_state: 1
    #algorithm: randomforest
    #arguments:
    #  n_estimators: 500
    #  target_transform: standardise

    algorithm: multirandomforest
    arguments:
       n_estimators: 2
       target_transform: standardise
       forests: 10
       parallel: True
       outdir: .


#n_components : int, float, None or string
#        Number of components to keep.
#        if n_components is not set all components are kept::
#        if n_components == 'mle' and svd_solver == 'full', Minka\'s MLE is used
#        to guess the dimension
#        if ``0 < n_components < 1`` and svd_solver == 'full', select the number
#        of components such that the amount of variance that needs to be
#        explained is greater than the percentage specified by n_components
#        n_components cannot be equal to n_features for svd_solver == 'arpack'.
# svd_solver: {'auto', 'full', 'arpack', 'randomized'}
# iterated power: int > 0 or 'auto'
# kde transform is not working yet

optimisation:
#  algorithm: randomforest
#  featuretransforms:
#    pca:
#      n_components: [0.5, 0.8]
#      whiten: [False, True]
#      svd_solver: ['auto']
#      iterated_power: ['auto']
#  hyperparameters:
#    n_estimators: [10, 50, 200]
#    target_transform: ['identity', 'standardise', 'log', 'rank', 'logistic']
#  optimisation_output: optimisation.csv

#  algorithm: gradientboost
#  featuretransforms:
#    pca:
#      n_components: [0.5, 0.8]
#      whiten: [False, True]
#      svd_solver: ['auto']
#      iterated_power: ['auto']
#  hyperparameters:
#    n_estimators: [10, 50, 200]
#    target_transform: ['identity', 'standardise', 'log', 'rank', 'logistic']
#  optimisation_output: optimisation.csv


# outbands: number of output bands desired.
# Bands (1:5): ['Prediction', 'Variance', 'Lower quantile',
# 'Upper quantile', 'Entropy']
prediction:
  quantiles: 0.95
  outbands: 1

validation:
  #- feature_rank
  - parallel
  - k-fold:
      folds: 5
      random_seed: 1
  
output:
  directory: .


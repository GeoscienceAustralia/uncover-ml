
experiment: my_run
patchsize: 0
memory_fraction: 0.5

intersected_features:
  "relief_apsect.tif": "relief4"
  "LATITUDE_GRID1.tif": "latitude"
  "LONGITUDE_GRID1.tif": "longitude"
  "er_depg.tif": "er_depg"
  "sagawet_b_sir.tif": "sagawet"
  "dem_foc2.tif": "dem_foc2"
  "outcrop_dis2.tif": "outcrop"
  "k_15v5.tif": "k_15v5"


features:
  - name: my continuous features
    type: continuous
    files:
      - path: configs/data/sirsam/relief_apsect.tif
      - path: configs/data/sirsam/LATITUDE_GRID1.tif
      - path: configs/data/sirsam/LONGITUDE_GRID1.tif
    transforms:
      - identity
#      - whiten:
#          keep_fraction: 0.98
    imputation: none
  - name: my 2nd continuous features
    type: continuous
    files:
      - path: configs/data/sirsam/er_depg.tif
      - path: configs/data/sirsam/sagawet_b_sir.tif
      - path: configs/data/sirsam/dem_foc2.tif
      - path: configs/data/sirsam/outcrop_dis2.tif
      - path: configs/data/sirsam/k_15v5.tif
    transforms:
      - identity
    #      - whiten:
    #          keep_fraction: 0.98
    imputation: none

preprocessing:
  imputation: none
  transforms:
#    - whiten:
#        keep_fraction: 0.98

targets:
#  file: configs/data/geochem_sites.shp
  file: configs/data/sirsam/out_resampled/geochem_sites.shp
  property: K_ppm_imp
  weight_col_name: K_ppm_imp_  # hack weight col
#  group_targets:
#    groups_eps: 0.09

learning:
  algorithm: gradientboost
  arguments:
    target_transform: identity
    loss: 'ls'
    max_depth: 20
    learning_rate: 0.1
    n_estimators: 100
    subsample: 0.9
    min_samples_split: 2
    min_samples_leaf: 2
    min_weight_fraction_leaf: 0.0
    max_features: "auto"
    alpha: 0.95
    random_state: 3
  optimisation:
    hyperopt_params:
      max_evals: 5
      step: 2
      cv: 2
      verbose: true
      random_state: 3
      scoring: r2  # r2, neg_mean_absolute_error, etc..see note above
      algo: bayes   # bayes, or anneal
    hp_params_space:
      max_depth: randint('max_depth', 1, 15)
      learning_rate: loguniform('learning_rate', -5, 0)
      n_estimators: randint('n_estimators', 5, 25)
      subsample: uniform('subsample', 0.01, 1.0)
      max_features: choice('max_features', ['auto', 'sqrt', 'log2'])
      min_samples_split: randint('min_samples_split', 2, 50)
      min_samples_leaf: randint('min_samples_leaf', 1, 50)
      min_weight_fraction_leaf: uniform('min_weight_fraction_leaf', 0.0, 0.5)
      max_leaf_nodes: randint('max_leaf_nodes', 10, 50)

    searchcv_params:
      n_iter: 6
      cv: 2
      verbose: 1000
      n_points: 3
      n_jobs: 6
    params_space:
      'max_depth': Integer(1, 15)
      'learning_rate': Real(10 ** -5, 10 ** 0, prior="log-uniform")
      'n_estimators': Integer(10, 100)
      'subsample': Real(0.01, 1.0, prior='uniform')
      'max_features': Categorical(['auto', 'sqrt', 'log2'])
      'min_samples_split': Integer(2, 50)
      'min_samples_leaf': Integer(1, 50)
      'min_weight_fraction_leaf': Real(0.0, 0.5, prior='uniform')
      'max_leaf_nodes': Integer(10, 50)

prediction:
#  corner_coordinates:
#    upper_left: ( 119.9670000, -26.9553333)
#    lower_right: ( 121.5253333, -28.0170000)
  quantiles: 0.95
  outbands: 1

validation:
  #- feature_rank
  - parallel
  - k-fold:
      folds: 3
      random_seed: 1

output:
  directory: gb/
